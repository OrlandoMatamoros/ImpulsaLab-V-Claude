// app/api/unified-agent/route.ts

import { GoogleGenerativeAI } from '@google/generative-ai';
import { NextResponse } from 'next/server';

// Cache simple en memoria
const responseCache = new Map();
const CACHE_DURATION = 3600000; // 1 hora en millisegundos

function getCacheKey(query: string) {
  return query.toLowerCase().trim();
}

export async function POST(request: Request) {
  try {
    const { query } = await request.json();
    
    if (!query) {
      return NextResponse.json(
        { error: 'Query is required' },
        { status: 400 }
      );
    }

    // Verificar cach√©
    const cacheKey = getCacheKey(query);
    const cached = responseCache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < CACHE_DURATION) {
      return NextResponse.json(cached.data);
    }

    // Inicializar respuestas
    const responses = {
      chatgpt: '',
      claude: '',
      gemini: '',
      unified: ''
    };

    // Promesas para consultas paralelas
    const aiPromises: Promise<void>[] = [];

    // 1. ChatGPT
    if (process.env.OPENAI_API_KEY) {
      aiPromises.push(
        fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              {
                role: 'system',
                content: 'Eres un experto en automatizaci√≥n empresarial. Responde de forma t√©cnica y espec√≠fica en m√°ximo 80 palabras.'
              },
              {
                role: 'user',
                content: query
              }
            ],
            max_tokens: 80,
            temperature: 0.7
          })
        })
        .then(res => res.json())
        .then(data => {
          responses.chatgpt = data.choices?.[0]?.message?.content || 'Error al obtener respuesta de ChatGPT';
        })
        .catch(err => {
          console.error('Error ChatGPT:', err);
          responses.chatgpt = 'ChatGPT: Analizando desde la perspectiva t√©cnica...';
        })
      );
    }

    // 2. Claude
    if (process.env.ANTHROPIC_API_KEY) {
      aiPromises.push(
        fetch('https://api.anthropic.com/v1/messages', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-api-key': process.env.ANTHROPIC_API_KEY,
            'anthropic-version': '2023-06-01'
          },
          body: JSON.stringify({
            model: 'claude-3-haiku-20240307', // Modelo m√°s econ√≥mico
            max_tokens: 80,
            messages: [
              {
                role: 'user',
                content: `Como experto en transformaci√≥n digital y gesti√≥n del cambio, responde en m√°ximo 80 palabras: ${query}`
              }
            ]
          })
        })
        .then(res => res.json())
        .then(data => {
          responses.claude = data.content?.[0]?.text || 'Error al obtener respuesta de Claude';
        })
        .catch(err => {
          console.error('Error Claude:', err);
          responses.claude = 'Claude: Considerando el impacto humano y organizacional...';
        })
      );
    }

    // 3. Gemini
    const geminiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;
    if (geminiKey) {
      const genAI = new GoogleGenerativeAI(geminiKey);
      const model = genAI.getGenerativeModel({ model: "gemini-pro" });
      
      aiPromises.push(
        model.generateContent(`Como especialista en IA y automatizaci√≥n empresarial, responde en m√°ximo 80 palabras: ${query}`)
          .then(result => {
            responses.gemini = result.response.text() || 'Error al obtener respuesta de Gemini';
          })
          .catch(err => {
            console.error('Error Gemini:', err);
            responses.gemini = 'Gemini: Analizando las mejores pr√°cticas del mercado...';
          })
      );
    }

    // Esperar todas las respuestas
    await Promise.all(aiPromises);

    // Generar respuesta unificada con Gemini
    if (geminiKey) {
      try {
        const genAI = new GoogleGenerativeAI(geminiKey);
        const model = genAI.getGenerativeModel({ model: "gemini-pro" });
        
        const unifiedPrompt = `
        Eres un experto unificador de IA. Bas√°ndote en estas 3 perspectivas sobre "${query}":
        
        ChatGPT (t√©cnica): ${responses.chatgpt}
        Claude (humana): ${responses.claude}
        Gemini (pr√°ctica): ${responses.gemini}
        
        Crea una s√≠ntesis ejecutiva que:
        1. Combine los mejores insights
        2. Elimine redundancias
        3. Presente una soluci√≥n clara
        4. Use emojis para destacar puntos clave
        
        Formato: 3-4 puntos concisos con acciones espec√≠ficas. M√°ximo 150 palabras.
        `;

        const unifiedResult = await model.generateContent(unifiedPrompt);
        responses.unified = unifiedResult.response.text();
      } catch (error) {
        // Respuesta unificada de respaldo
        responses.unified = `üéØ S√çNTESIS UNIFICADA 4IA:

‚úÖ **Perspectiva T√©cnica**: ${responses.chatgpt.substring(0, 60)}...

‚úÖ **Perspectiva Humana**: ${responses.claude.substring(0, 60)}...

‚úÖ **Perspectiva Pr√°ctica**: ${responses.gemini.substring(0, 60)}...

üí° **Recomendaci√≥n Impulsa Lab**: Implementa una soluci√≥n gradual que combine automatizaci√≥n t√©cnica con gesti√≥n del cambio.`;
      }
    }

    // Guardar en cach√©
    responseCache.set(cacheKey, {
      data: responses,
      timestamp: Date.now()
    });

    return NextResponse.json(responses);

  } catch (error) {
    console.error('Error general:', error);
    // Respuestas de fallback
    return NextResponse.json({
      chatgpt: 'Perspectiva t√©cnica: Implementa automatizaci√≥n con herramientas no-code como Make o Zapier.',
      claude: 'Perspectiva humana: Considera el impacto en tu equipo y capac√≠talos gradualmente.',
      gemini: 'Perspectiva pr√°ctica: Comienza con procesos simples y escala progresivamente.',
      unified: 'üéØ Recomendaci√≥n: Inicia con un piloto peque√±o, mide resultados y expande.'
    });
  }
}

// Endpoint para verificar el estado de las APIs
export async function GET() {
  const status = {
    openai: !!process.env.OPENAI_API_KEY,
    anthropic: !!process.env.ANTHROPIC_API_KEY,
    gemini: !!(process.env.GEMINI_API_KEY || process.env.GOOGLE_GEMINI_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY),
  };

    return NextResponse.json({
      status,
      message: 'API status check',
      cache_size: responseCache.size
    });
  }